{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, exists\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import daisy,hog\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "import skimage\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "import sklearn.cluster\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"Dataset2/\"\n",
    "categories_name = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airport_terminal', 'art_gallery', 'art_studio', 'childs_room']\n"
     ]
    }
   ],
   "source": [
    "print(categories_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_path(path):\n",
    "    file = [path+f for f in listdir(path) if isfile(join(path, f))]\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "file = []\n",
    "for cat in categories_name:\n",
    "    files  = file_path(directory + cat +\"/\")\n",
    "    for f in files:\n",
    "        file.append(f)\n",
    "        labels.append(categories_name.index(cat))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files,test_files,train_labels,test_labels=train_test_split(file,labels,test_size=0.4,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_descriptors(image,hog_pixels_per_cell=16,hog_cells_per_block=1):\n",
    "   \n",
    "    hog_descriptor=hog(image, orientations=8, pixels_per_cell=(hog_pixels_per_cell, hog_pixels_per_cell),cells_per_block=(hog_cells_per_block, hog_cells_per_block), visualise = False,feature_vector=True)\n",
    "    \n",
    "    hog_descriptor = hog_descriptor.reshape(len(hog_descriptor),1)\n",
    "    return hog_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_daisy_descriptors(image,daisy_step_size=32,daisy_radius=32):\n",
    "        d = daisy(image, step=daisy_step_size, radius=daisy_radius, rings=2, histograms=8,orientations=8, visualize=False)\n",
    "        num_of_descriptor = d.shape[0] * d.shape[1]\n",
    "        daisy_desriptors=d.reshape(num_of_descriptor,d.shape[2])\n",
    "        return daisy_desriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/190 [00:00<?, ?it/s]C:\\Users\\MOHIT\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\MOHIT\\Anaconda3\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 190/190 [06:55<00:00,  2.35s/it]\n"
     ]
    }
   ],
   "source": [
    "hog_descriptor_list = []\n",
    "daisy_descriptor_list = []\n",
    "HOG_AND_DAISY_FEATURES = {}\n",
    "for file_path in tqdm(train_files):\n",
    "   \n",
    "    image = io.imread(file_path)\n",
    "    image_gray = rgb2gray(image)\n",
    "    \n",
    "    image=skimage.transform.resize(image_gray,(700,700))\n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n",
    "    hog_descriptor = extract_hog_descriptors(image)\n",
    "    daisy_descriptor = extract_daisy_descriptors(image, daisy_step_size=8,daisy_radius=8)\n",
    "    HOG_AND_DAISY_FEATURES[file_path] = [hog_descriptor,daisy_descriptor]\n",
    "    hog_descriptor_list =  hog_descriptor_list + list(hog_descriptor)\n",
    "    daisy_descriptor_list = daisy_descriptor_list + list(daisy_descriptor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1405240"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(daisy_descriptor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(daisy_descriptor,number_of_clusters):\n",
    "    km=MiniBatchKMeans(n_clusters=number_of_clusters,batch_size=number_of_clusters*1)\n",
    "    km.fit(daisy_descriptor)\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model = clustering(daisy_descriptor,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=1000, compute_labels=True, init='k-means++',\n",
       "        init_size=None, max_iter=100, max_no_improvement=10,\n",
       "        n_clusters=1000, n_init=3, random_state=None,\n",
       "        reassignment_ratio=0.01, tol=0.0, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_descriptor(file, cluster_model):\n",
    "    \n",
    "    if file in HOG_AND_DAISY_FEATURES:\n",
    "        daisy_feature = HOG_AND_DAISY_FEATURES[file][1]\n",
    "        hog_feature = HOG_AND_DAISY_FEATURES[file][0]\n",
    "    else:\n",
    "        image = io.imread(file)\n",
    "        image_gray = rgb2gray(image)\n",
    "\n",
    "        image=skimage.transform.resize(image_gray,(700,700))\n",
    "        hog_feature = extract_hog_descriptors(image)\n",
    "        daisy_feature = extract_daisy_descriptors(image, daisy_step_size=8,daisy_radius=8)\n",
    "        #HOG_AND_DAISY_FEATURES[file_path] = [file,daisy_feature]\n",
    "        #hog_descriptor_list =  hog_descriptor_list + list(hog_feature)\n",
    "        #daisy_descriptor_list = daisy_descriptor_list + list(daisy_feature)\n",
    "        \n",
    "    image_cluster_prediction = cluster_model.predict(daisy_feature)\n",
    "    cluster_freq_counts=pd.DataFrame(image_cluster_prediction,columns=['cnt'])['cnt'].value_counts()\n",
    "    bovw_vector=np.zeros(cluster_model.n_clusters)\n",
    "    #print(len(image_cluster_prediction))\n",
    "    #print(len(cluster_freq_counts))\n",
    "    #bovw_vector=np.zeros(daisy_cluster_model.n_clusters)\n",
    "    for key in cluster_freq_counts.keys():\n",
    "        bovw_vector[key]=cluster_freq_counts[key]\n",
    "\n",
    "    bovw_feature=bovw_vector/np.linalg.norm(bovw_vector)\n",
    "    hog_feature=hog_feature/np.linalg.norm(hog_feature)\n",
    "    \n",
    "    return list(bovw_feature)+list(hog_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "i = 0;\n",
    "for file in train_files:\n",
    "    X_train.append(hybrid_descriptor(file, cluster_model))\n",
    "    Y_train.append(train_labels[i])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc = svm.LinearSVC()\n",
    "hc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=47.798477392518556, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma=0.6869173242795459,\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_classifier=svm.SVC(C=10**1.6794140624999994, gamma=10**-0.1630955304365928, decision_function_shape='ovo') #cross-validated hyper-parameters\n",
    "hybrid_classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOHIT\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\MOHIT\\Anaconda3\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "X_Test = []\n",
    "Y_Test = []\n",
    "i = 0\n",
    "for file in test_files:\n",
    "    X_Test.append(hybrid_descriptor(file, cluster_model))\n",
    "    Y_Test.append(test_labels[i])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2810480"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hog_descriptor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybridpred1 = hybrid_classifier.predict(X_Test)\n",
    "hybridpred2 = hc.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.7401574803149606\n"
     ]
    }
   ],
   "source": [
    "print ('Overall accuracy:',accuracy_score(Y_Test,hybridpred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.6929133858267716\n"
     ]
    }
   ],
   "source": [
    "print ('Overall accuracy:',accuracy_score(Y_Test,hybridpred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
